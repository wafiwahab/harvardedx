---
title: "Capstone - Movie Ratings Prediction"
output:
  html_notebook:
    fig_caption: yes
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    df_print: paged
date: "`r format(Sys.time(), '%d %B %Y')`"
---

```{r setup, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# Executive Summary
This is a capstone project for [HarvardX Data Science - Professional Certificate](http://rmarkdown.rstudio.com) program. 
Objective of project is to create a move recommendation system using MovieLens dataset, using all tools (in particular ML algorithms) shown throught-out the HarvardX DS program.

## Dataset
Data assigned for this project is the 10 million ratings version of the [MovieLens dataset](https://grouplens.org/datasets/movielens/10m/).
There are 72K users in this dataset.
The dataset is created as follows:

```{r lib_packages, warning=FALSE, message=FALSE}

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(stringr)
library(knitr)
library(kableExtra)
```
# Data Prep - Extract, transform, load train and validation set.

```{r etl_stage, echo = TRUE}

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

# data extraction as recommended on HarvardX
#dl <- tempfile()
#download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

#ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 #col.names = c("userId", "movieId", "rating", "timestamp"))

#movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
#colnames(movies) <- c("movieId", "title", "genres")


# if using R 4.0 or later:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           #title = as.character(title),
                                           #genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# data transformation - cleaning 
# UTC timestamp into date, identify movie release year
movielens <- movielens %>%
  mutate(rating_timedate = as_datetime(timestamp)) %>% 
  mutate(rating_date = date(as_datetime(timestamp))) %>% 
  mutate(rating_hour = hour(as_datetime(timestamp))) %>% 
  mutate(release_yr = parse_number(str_sub(title, -6, -1))) %>%
  mutate(title = str_trim(str_sub(title, 1, -7))) %>%
  select(-timestamp)
  
# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

#rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

#### Data familiarization

```{r dim}
rows <- dim(edx)[1]
cols <- dim(edx)[2]
```
The `edx` training dataset has `r rows` rows (number of ratings) and  `r cols` columns.  

#### Exploratory Data Analysis
##### Rating Distribution

Frequency distribution of ratings are shown in table 1 and figure 1 below:
```{r rating_freq_tab}
rft <- descr::freq(as.factor(edx$rating), plot = FALSE)
zero_rating <- edx %>% filter(rating == 0) %>%
  nrow()
three_rating <- edx %>% filter(rating == 3) %>%
  nrow()
kable(rft)
```

No. of ratings given zero = `r zero_rating`.
No. of ratings given three = `r three_rating`.
Top 4 most given ratings in order from most to least - 4, 3, 5, 3.5, 2-; and Half star (.5) ratings are less common than whole stars.

```{r rating_hist, fig.cap = "Fig. 1.1 Freq. dist. of ratings."}
library(scales)
x <- seq(0, 5, 0.5)
edx %>% ggplot(aes(x = rating)) +
  geom_histogram(binwidth = 0.5, alpha=0.9) +
  stat_bin(binwidth = 0.5, geom ="text", aes(label = ..count..), vjust = -1.5) +
  theme_classic() +
  scale_y_continuous(label = label_number_si(), limits = c(0, 3e6)) +
  scale_x_continuous(labels = as.character(x) ,breaks = x)
```

No. of distinct movies rated = `r n_movies`.

```{r n_distinct_movies}
n_movies <- n_distinct(edx$movieId)
n_movies
```
No. of distinct movies by rating
```{r movie_dist_rating, fig.cap = "Fig 1.2 # of unique movies by ratings"}
edx %>% group_by(rating) %>% summarize(n_mov = n_distinct(movieId)) %>%
  ggplot(aes(x = rating, y = n_mov)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label= n_mov, vjust = -1.5)) +
  ylim(0, 12500) +
  scale_x_continuous(labels = as.character(x) ,breaks = x) +
  ylab("no of movies") +
  theme_classic()
```

No. of unique users = `r n_users`.
```{r n_unique_users}
n_users <- n_distinct(edx$userId)
n_users
```

No. of distinct users by rating
```{r user_dist_rating, fig.cap = "Fig 1.3 # of unique users by ratings"}
edx %>% group_by(rating) %>% summarize(n_user = n_distinct(userId)) %>%
  ggplot(aes(x = rating, y = n_user)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label= n_user, vjust = -1.5)) +
  scale_y_continuous(labels = label_number_si(), limits = c(0, 80000)) +
  scale_x_continuous(labels = as.character(x) ,breaks = x) +
  ylab("no of users") +
  theme_classic()
```

Genre stats
No. of unique genre combinations
```{r n_distinct_genre_combo}
n_genres_combo <- n_distinct(edx$genres)
n_genres_combo
```

Genres that are available in the dataset include:
```{r distinct_genres}
n_drama <- edx %>% filter(str_detect(edx$genres, "Drama") == TRUE) %>% summarize(n = n())

#starttime <- Sys.time()

#genre_tab <- edx[,c(1:2,6)] %>% separate_rows(genres, sep = "\\|") %>%
  #group_by(genres) %>%
  #summarize(n_movies = n_distinct(movieId), n_ratings = n(),
            #n_users = n_distinct(userId)) 
#endtime <- Sys.time()

#duration <- endtime - starttime
#duration #18.7mins 
#is there a faster way? need to extract full list of genres follower by str_detect and sum.

kable(arrange(genre_tab, desc(n_movies),
              desc(n_ratings),
              desc(n_users)),
      format = "html",
      caption = "Table 1.1 ") %>%
  kable_styling()

genre_prop_tab <- genre_tab %>%
  mutate(n_mov_prop = round(n_movies/sum(n_movies)*100, 1)) %>%
  mutate(n_rat_prop = round(n_ratings/sum(n_ratings)*100, 1)) %>%
  mutate(n_users_prop = round(n_users/sum(n_users)*100, 1)) %>%
  select(n_mov_prop, n_rat_prop, n_users_prop)
genre_prop_tab %>% kable(arrange(genre_tab, desc(n_mov_prop),
              desc(n_rat_prop),
              desc(n_users_prop)),
      format = "html",
      caption = "Table 1.2",
      col.names = c("Genre", "% Freq Movies", "%Freq Ratings",
                    "%Freq Users")) %>%
  kable_styling()
```

No. of movie ratings for Drama genre is `r n_drama`.
```{r no_genre&imax_movie}
#find out which movies are IMAX and no genre
```


```{r genre_mov_dist, fig.cap = "Fig 1.3 No. of movies by Genres" }
p <- genre_tab %>% ggplot(aes(x = reorder(genres, -n_movies), y = n_movies)) +
  geom_bar(stat = "identity")
p <- p +
  labs(x = "genres",
       y = "# of movies") +
  coord_flip() +
  theme_classic() #most common genre is Drama
p + geom_text(aes(label = n_movies), vjust = 0, hjust = -0.5) +
  ylim(c(0, 6000))
```


```{r genre_combo_mov_dist, fig.cap = "Fig 1.4 Most Popular Genre Combinations"}
p2 <- edx %>% group_by(genres) %>% 
  summarize(n_movies = n_distinct(movieId)) %>%
  filter(n_movies > 100) %>%
  ggplot(aes(x = reorder(genres, -n_movies), y = n_movies)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n_movies), hjust = -0.5) +
  ylim(c(0,2000))
p2 <- p2 + coord_flip() +
  theme_classic() +
  labs(y = "# of movies",
       x = "genres")
p2
```

Indicates in terms of genres, there is a higher proportion of movies in the database
that are combination of drama, comedy romance. Followed by documentary & horror.

```{r - n_ratings_by_movie}
title_freqtab <- edx %>% group_by(title) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(50)
title_freqtab

movie_titles <- c("Forrest Gump", "Jurassic Park", "Pulp Fiction",
                  "The Shawshank Redemptioin",
                  "Speed 2: Cruise Control")

edx %>% filter(title %in% movie_titles) %>%
  group_by(title) %>%
  summarize(count = n()) %>% arrange(desc(count))
```

## Movie Rating Prediction

Movie ratings generated to be compared to true ratings in `r validation` set using RMSE

### Method/Analysis
```{r eda1}
## check data type for both test and validation set may need to adjust above
str(edx)
str(validation)

## transform data type to appropriate data type
## identified some problems with release year data - clean up
# provide some description son rating date and rating hour derived from time stamp above.
# solve the knit on save issue, knit it now.
```


## Results
```{r}
#features- release year, title, 

```

## Conclusion
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
