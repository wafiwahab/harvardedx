---
title: "Capstone - Movie Ratings Prediction"
output:
  html_notebook:
    fig_caption: yes
    toc: yes
    toc_float: yes
  html_document:
    toc: yes
    df_print: paged
date: "`r format(Sys.time(), '%d %B %Y')`"
---

```{r setup, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

# Executive Summary
This is a capstone project for [HarvardX Data Science - Professional Certificate](http://rmarkdown.rstudio.com) program. 
Objective of project is to create a move recommendation system using MovieLens dataset, using all tools (in particular ML algorithms) shown throught-out the HarvardX DS program.

## Dataset
Data assigned for this project is the 10 million ratings version of the [MovieLens dataset](https://grouplens.org/datasets/movielens/10m/).
There are 72K users in this dataset.
The dataset is created as follows:

```{r lib_packages, include = FALSE, warning=FALSE, message=FALSE}

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(stringr)
library(knitr)
library(kableExtra)
library(scales)
```
# Data Prep - Extract, transform, load train and validation set.

```{r etl_stage, echo = TRUE}

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

# data extraction as recommended on HarvardX
#dl <- tempfile()
#download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

#ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 #col.names = c("userId", "movieId", "rating", "timestamp"))

#movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
#colnames(movies) <- c("movieId", "title", "genres")


# if using R 4.0 or later:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           #title = as.character(title),
                                           #genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# data transformation - cleaning 
# UTC timestamp into date, identify movie release year
movielens <- movielens %>%
  mutate(rating_timedate = as_datetime(timestamp)) %>% 
  mutate(rating_date = date(as_datetime(timestamp))) %>% 
  mutate(rating_hour = hour(as_datetime(timestamp))) %>% 
  mutate(release_yr = parse_number(str_sub(title, -6, -1))) %>%
  mutate(title = str_trim(str_sub(title, 1, -7))) %>%
  select(-timestamp)
  
# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

#rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

#### Data familiarization

```{r dim}
rows <- dim(edx)[1]
cols <- dim(edx)[2]
```
The `edx` training dataset has `r rows` rows (number of ratings) and  `r cols` columns.  

#### Exploratory Data Analysis
##### Rating Distribution

Frequency distribution of ratings are shown in table 1 and figure 1 below:
```{r rating_freq_tab}
rft <- descr::freq(as.factor(edx$rating), plot = FALSE)
zero_rating <- edx %>% filter(rating == 0) %>%
  nrow()
three_rating <- edx %>% filter(rating == 3) %>%
  nrow()
kable(rft)
```

No. of ratings given zero = `r zero_rating`.
No. of ratings given three = `r three_rating`.
Top 4 most given ratings in order from most to least - 4, 3, 5, 3.5, 2-; and Half star (.5) ratings are less common than whole stars.

```{r rating_hist, fig.cap = "Fig. 1.1 Freq. dist. of ratings."}
library(scales)
x <- seq(0, 5, 0.5)
edx %>% ggplot(aes(x = rating)) +
  geom_histogram(binwidth = 0.5, alpha=0.9) +
  stat_bin(binwidth = 0.5, geom ="text", aes(label = ..count..), vjust = -1.5) +
  theme_classic() +
  scale_y_continuous(label = label_number_si(), limits = c(0, 3e6)) +
  scale_x_continuous(labels = as.character(x) ,breaks = x)
```

No. of distinct movies rated = `r n_movies`.

```{r n_distinct_movies}
n_movies <- n_distinct(edx$movieId)
n_movies
```
No. of distinct movies by rating
```{r movie_dist_rating, fig.cap = "Fig 1.2 # of unique movies by ratings"}
edx %>% group_by(rating) %>% summarize(n_mov = n_distinct(movieId)) %>%
  ggplot(aes(x = rating, y = n_mov)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label= n_mov, vjust = -1.5)) +
  ylim(0, 12500) +
  scale_x_continuous(labels = as.character(x) ,breaks = x) +
  ylab("no of movies") +
  theme_classic()
```

No. of unique users = `r n_users`.
```{r n_unique_users}
n_users <- n_distinct(edx$userId)
n_users
```

No. of distinct users by rating
```{r user_dist_rating, fig.cap = "Fig 1.3 # of unique users by ratings"}
edx %>% group_by(rating) %>% summarize(n_user = n_distinct(userId)) %>%
  ggplot(aes(x = rating, y = n_user)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label= n_user, vjust = -1.5)) +
  scale_y_continuous(labels = label_number_si(), limits = c(0, 80000)) +
  scale_x_continuous(labels = as.character(x) ,breaks = x) +
  ylab("no of users") +
  theme_classic()
```

Genre stats
No. of unique genre combinations
```{r n_distinct_genre_combo}
n_genres_combo <- n_distinct(edx$genres)
n_genres_combo
```

Genres that are available in the dataset include:
```{r distinct_genres}
n_drama <- edx %>% filter(str_detect(edx$genres, "Drama") == TRUE) %>% summarize(n = n())

#starttime <- Sys.time()

#genre_tab <- edx[,c(1:2,6)] %>% separate_rows(genres, sep = "\\|") %>%
  #group_by(genres) %>%
  #summarize(n_movies = n_distinct(movieId), n_ratings = n(),
            #n_users = n_distinct(userId)) 
#endtime <- Sys.time()

#duration <- endtime - starttime
#duration #18.7mins 
#is there a faster way? need to extract full list of genres follower by str_detect and sum.

kable(arrange(genre_tab, desc(n_movies),
              desc(n_ratings),
              desc(n_users)),
      format = "html",
      caption = "Table 1.1 ") %>%
  kable_styling()

genre_prop_tab <- genre_tab %>%
  mutate(n_mov_prop = round(n_movies/sum(n_movies)*100, 1)) %>%
  mutate(n_rat_prop = round(n_ratings/sum(n_ratings)*100, 1)) %>%
  mutate(n_users_prop = round(n_users/sum(n_users)*100, 1)) %>%
  select(n_mov_prop, n_rat_prop, n_users_prop)
genre_prop_tab %>% kable(arrange(genre_tab, desc(n_mov_prop),
              desc(n_rat_prop),
              desc(n_users_prop)),
      format = "html",
      caption = "Table 1.2",
      col.names = c("Genre", "% Freq Movies", "%Freq Ratings",
                    "%Freq Users")) %>%
  kable_styling()
```

No. of movie ratings for Drama genre is `r n_drama`.
```{r no_genre&imax_movie}
#find out which movies are IMAX and no genre
```


```{r genre_mov_dist, fig.cap = "Fig 1.3 No. of movies by Genres" }
p <- genre_tab %>% ggplot(aes(x = reorder(genres, -n_movies), y = n_movies)) +
  geom_bar(stat = "identity")
p <- p +
  labs(x = "genres",
       y = "# of movies") +
  coord_flip() +
  theme_classic() #most common genre is Drama
p + geom_text(aes(label = n_movies), vjust = 0, hjust = -0.5) +
  ylim(c(0, 6000))
```


```{r genre_combo_mov_dist, fig.cap = "Fig 1.4 Most Popular Genre Combinations"}
p2 <- edx %>% group_by(genres) %>% 
  summarize(n_movies = n_distinct(movieId)) %>%
  filter(n_movies > 100) %>%
  ggplot(aes(x = reorder(genres, -n_movies), y = n_movies)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n_movies), hjust = -0.5) +
  ylim(c(0,2000))
p2 <- p2 + coord_flip() +
  theme_classic() +
  labs(y = "# of movies",
       x = "genres")
p2
```

Indicates in terms of genres, there is a higher proportion of movies in the database
that are combination of drama, comedy romance. Followed by documentary & horror.

```{r - n_ratings_by_movie}
title_freqtab <- edx %>% group_by(title) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(50)
title_freqtab

movie_titles <- c("Forrest Gump", "Jurassic Park", "Pulp Fiction",
                  "The Shawshank Redemptioin",
                  "Speed 2: Cruise Control")

edx %>% filter(title %in% movie_titles) %>%
  group_by(title) %>%
  summarize(count = n()) %>% arrange(desc(count))
```

## Movie Rating Prediction

Movie ratings generated to be compared to true ratings in `r validation` set using RMSE

### Method/Analysis
```{r eda1}

edx %>% str() # overview of cleaned dataset
edx[,c(3, 7, 8)] %>% summary() #overview of numerical data

# enriching data to help in creating date/time based eda plots
edx <- edx %>% mutate(rating_month = month(rating_date)) %>%
  mutate(rating_year = year(rating_date)) %>%
  mutate(rating_mmmyy = as.Date(format(rating_date, "%Y-%m-01")))

rate_mmmyy <- edx %>% 
  group_by(rating_mmmyy, rating_month, rating_year) %>%
  summarize(count = n()) %>%
  mutate(rating_month2 = as.Date(paste0("2022-", rating_month, "-01"), "%Y-%m-%d")) %>%
  as.data.frame()

# chart showing no. of ratings by month & year
rate_mmmyy %>%
  ggplot(aes(x = rating_month2, y = count)) +
  geom_col() +
  facet_wrap(~ rating_year, ncol = 3) +
  labs(title = "Quantity of ratings over time",
       subtitle = "by day",
       y = "# of ratings ") +
  theme(axis.title.x = element_blank()) +
  scale_x_date(date_labels = "%b") +
  scale_y_continuous(labels = comma)
# data captures 14-15 years worth of ratings submitted from 1995 to 2009

# chart showing movies that rate in terms of release years
rate_mov_mmmyy <- edx %>%
  group_by(release_yr) %>%
  summarize(count = n()) %>%
  mutate(release_yr2 = as.Date(paste0(release_yr, "-01", "-01"), "%Y-%m-%d")) %>%
  as.data.frame()

rate_mov_mmmyy %>% ggplot(aes(x = release_yr2, y = count)) +
  geom_col() +
  scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
  scale_y_continuous(labels = comma) +
  labs(x = "Movie release year", y = "no. of ratings")
# movies that receive most ratings are movies released in the years 1990 - 2000
# movies released in 1995, received most no. of ratings

# opportunity to introduce a % frequency
edx %>% ggplot(aes(release_yr)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_x_binned(n.breaks = 20) +
  labs( x = "Movie release year", y = "Cumulative % Freq",
        title = "Empirical Cumulative Density Freq",
        subtitle = "# of ratings over release year")

# of movies released in each year?
edx %>% group_by(release_yr) %>%
  summarize(mov_count = n_distinct(movieId)) %>%
  arrange(desc(mov_count)) %>%
  ggplot(aes(x = release_yr, y = mov_count)) +
  geom_col() + 
  scale_x_continuous(breaks = round(seq(min(edx$release_yr), max(edx$release_yr), by = 5), 1))
# chart shows that no. of movies released per year increase over time post 1990 
# of movies releases per year increase 3x

# exploring no. of ratings received based on age of movie
edx_movage <- edx %>% mutate(mov_age = 2010 - release_yr) %>%
  group_by(mov_age) %>%
  summarize(mov_count = n_distinct(movieId),
            n_ratings = n(),
            arpmov = n_ratings/mov_count,
            avg_rating = mean(rating),
            var_rating = sd(rating),
            n_users = n_distinct(userId),
            anratingpu = n_ratings/n_users) %>%
  arrange(desc(arpmov))

u1 <- edx_movage %>% ggplot(aes(x = mov_age, colour = "A#RPU")) +
  geom_line(aes(y = anratingpu))
u1 <- u1 + geom_line(aes(y = n_users/6000, colour = "NUSERS"))
u1 <- u1 + scale_y_continuous(sec.axis = sec_axis(~.*6000, name = "no. of users")) +
  labs(y = "Avg # of ratings per user", x = "Age of Movie",
       colour = "Parameter")
u1 + theme(legend.position = c(0.8, 0.9))
#interested to see correlation between
# no. of ratings and variance of ratings
cor(edx_movage$n_ratings, edx_movage$var_rating)
cor(edx_movage$mov_age, edx_movage$var_rating)

p <- cor(edx_movage)
corrplot::corrplot(p)
# as movie age increases, less #of movies, ratings, # of ratings per movie,
# avg rating increases, but there is less variance and less no. of distinct users

edx_movage %>% ggplot(aes(x = mov_age, y = arpmov)) +
  geom_point() +
  scale_x_continuous(breaks = c(seq(0, max(edx_movage$mov_age + 10), 5))) +
  scale_y_continuous(labels = comma) +
  ylab("Avg # of rating per movie") +
  xlab("Age of movie")

p1 <- edx_movage %>% ggplot(aes(x = as.factor(mov_age), y = avg_rating)) +
  geom_point() +
  scale_y_continuous(breaks = c(seq(0, 5, 0.5))) +
  ylim(0, 5)
p1

#older movies seem to have a higher average score s-curve
set.seed(1, sample.kind="Rounding")
p2 <- edx %>% sample_n(10000) %>%
  mutate(mov_age = 2010 - release_yr) %>%
  mutate(mov_age = as.factor(mov_age)) %>%
  ggplot(aes(x = mov_age, y = rating)) +
  geom_boxplot() +
  geom_jitter(size = 0.05, alpha = 0.5) 
p2

p3 <- edx %>% sample_n(10000) %>%
  mutate(mov_age = 2010 - release_yr) %>%
  ggplot(aes(x = rating, y = mov_age)) + 
  geom_violin() +
  scale_y_continuous(breaks = c(seq(0, 100, 5)))
p3 # movies between 10 & 20 yrs of age have higher diversity (variance) of ratings

edx %>% 

# chart showing no. of ratings submitted by time (hour) of day
edx %>% ggplot(aes(rating_hour)) +
  geom_histogram() +
  scale_x_continuous(breaks = c(seq(0,23, 1)))


edx %>% group_by(rating_hour) %>%
  summarize(avgrating_byhr = mean(rating))
#rating average pretty constant across hour of day

# candlesticks chart see any variation within hour of day
set.seed(1, sample.kind="Rounding")
edx %>% sample_n(10000) %>% ggplot(aes(x = as.factor(rating_hour), y = rating)) +
  geom_boxplot() +
  geom_jitter(size = 0.05, alpha = 0.5)

n_users*n_movies # of possible ratings 746.09M
# spare matrix (randomly select 100 movies and 100 users) -> create image plot
# plot of no. of ratings vs users and movies
```


## Results
```{r}


```

## Conclusion
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
